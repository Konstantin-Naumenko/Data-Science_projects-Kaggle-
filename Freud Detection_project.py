# -*- coding: utf-8 -*-
"""Дипломный проект_Науменко К.Л..ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HzFKvf17jmILh5ZqOufR4u7aMbLhj3GC

# Описание задачи

**Задача классификации. Определить является ли операция мошеннической (1) или нет (0).**
- Датасет содержит иноформацию о транзакциях, совершенных по кредитным картам в сентябре 2013 года держателями карт из Европы.
- Датасет содержит информацию о транзакциях за два дня, среди которых было 492 случая мошенничества (0,172%) из 284807 транзакций (до удаления дупликатов).
Датасет содержит только числовые входные переменные. Признаки V1 - V28 являются основными компонентами, полученными с помощью преобразования методом главных компонент (PCA).
- Признаки "Время" ("Time") и "Количество" ("Amount") не были преобразованы с помощью PCA. Колонка "Класс" ("Class") является ответом (1 - мошенничество, 0 - нет).
Признак «Time» отражает секунды, прошедшие между данной транзакцией и первой транзакцией в датасете. 
- Функция «Amount» — это сумма транзакции, эту функцию можно использовать, например, для зависимого от затрат обучения (dependant cost-sensitive learning).
- Учитывая коэффициент дисбаланса классов, рекомендуется измерять точность с помощью площади под кривой точности-полноты (AUPRC). Точность матрицы ошибок (Confusion matrix) не имеет значения для несбалансированной классификации.
"""

# ссылка на Kaggle https://www.kaggle.com/mlg-ulb/creditcardfraud
# ссылка на ноутбук https://colab.research.google.com/drive/1GaudFXuSOK2s_w9DQF1xFE7ndxZYdkdu?usp=sharing

"""#Импорт библиотек"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib
from matplotlib import pyplot as plt
# %matplotlib inline

"""#Загрузка данных"""

#загрузка с локального диска
#from google.colab import files
#uploaded = files.upload()
#df = pd.read_csv("C://Users//leo-v//OneDrive//Документы//Учеба 2035//Диплом//creditcard.csv", "r")
#df.head()

# загрузка по ссылке
!pip install --upgrade --no-cache-dir gdown
import gdown
id = "1RCdKRHjMijAlx8HAtk9H4rpE1yaV9fPk"
output = 'creditcard.csv'
gdown.download(id=id, output=output, quiet=False)

df = pd.read_csv('creditcard.csv')
df

"""# Первичная обработка

"""

df.describe()

df.info()

# проверили на отсутствие пропусков
df.isnull().sum()

# удалили дубликаты
df.drop_duplicates(inplace=True)

# операции с признаками мошенничества 0,1668%
df['Class'].value_counts()

# построим график распределения классов
fig, ax = plt.subplots(1, 1)
ax.pie(df.Class.value_counts(),autopct='%1.3f%%', labels=['Correct','Fraud'], colors=['bisque','maroon'])
plt.axis('equal')
plt.ylabel('')

# узнаем кол-во уникальных элементов по признакам  
print('Уникальные значения признаков и целевой переменной:')
print('Time:', len(df['Time'].unique()))
print('V1:', len(df['V1'].unique()))
print('V2:', len(df['V2'].unique()))
print('V3:', len(df['V3'].unique()))
print('V4:', len(df['V4'].unique()))
print('V5:', len(df['V5'].unique()))
print('V6:', len(df['V6'].unique()))
print('V7:', len(df['V7'].unique()))
print('V8:', len(df['V8'].unique()))
print('V9:', len(df['V9'].unique()))
print('V10:', len(df['V10'].unique()))
print('V11:', len(df['V11'].unique()))
print('V12:', len(df['V12'].unique()))
print('V13:', len(df['V13'].unique()))
print('V14:', len(df['V14'].unique()))
print('V15:', len(df['V15'].unique()))
print('V16:', len(df['V16'].unique()))
print('V17:', len(df['V17'].unique()))
print('V18:', len(df['V18'].unique()))
print('V19:', len(df['V19'].unique()))
print('V20:', len(df['V20'].unique()))
print('V21:', len(df['V21'].unique()))
print('V22:', len(df['V22'].unique()))
print('V23:', len(df['V23'].unique()))
print('V24:', len(df['V24'].unique()))
print('V25:', len(df['V25'].unique()))
print('V26:', len(df['V26'].unique()))
print('V27:', len(df['V27'].unique()))
print('V28:', len(df['V28'].unique()))

print('Amount:', len(df['Amount'].unique()))
print('Class:', len(df['Class'].unique()))

df['Time'].value_counts()

df['V1'].value_counts()

df['Amount'].value_counts()

# операции с признаками мошенничества
df_class_1 = df.loc[df['Class'] == 1.0]
df_class_0 = df.loc[df['Class'] == 0.0]

fig = plt.figure(figsize=(24,24))
cols = 5
rows = int(np.ceil(float(df.shape[1]) / cols))
for i, column in enumerate(df.columns):
    ax = fig.add_subplot(rows, cols, i + 1)
    ax.set_title(column)
    df[column].hist(axes=ax)
    plt.xticks(rotation="vertical")
plt.subplots_adjust(hspace=0.7, wspace=0.2)

legit = df[df["Class"] == 0]
fraud = df[df["Class"] == 1]

ls = legit.sample(n=fraud.Class.value_counts()[1])
ls.Class.value_counts()
print(f'Fraud : {fraud.Class.value_counts()[1]} &  Legit : {legit.Class.value_counts()[0]}')
df2 = pd.concat([fraud,ls], axis = 0)
df2

# НЕСбалансированная Матрица корреляций между параметрами
import seaborn as sns
f, ax = plt.subplots(figsize=(15, 15))
# ax = sns.heatmap(df.corr(),  cmap='coolwarm', fmt='.2g', annot=True)
sns.heatmap(df.corr(),
            square = True,
            linewidths = .5,
            # mask = mask,
            cmap = 'coolwarm',
            cbar_kws = {'shrink': .4,"ticks" : [-1, -.5, 0, 0.5, 1]},
            vmin = -1,
            vmax = 1,
            fmt='.1f',
            annot = True,
            annot_kws = {"size": 8},
            ax = ax)

# Сбалансированная Матрица корреляций между параметрами
import seaborn as sns
f, ax = plt.subplots(figsize=(15, 15))
mask = np.zeros_like(df.corr(), dtype=np.bool)
mask[np.triu_indices_from(mask)]= True
# ax = sns.heatmap(df.corr(),  cmap='coolwarm', fmt='.2g', annot=True)
sns.heatmap(df2.corr(),
            square = True,
            linewidths = .5,
            # mask = mask,
            cmap = 'coolwarm',
            cbar_kws = {'shrink': .4,"ticks" : [-1, -.5, 0, 0.5, 1]},
            vmin = -1,
            vmax = 1,
            fmt='.1f',
            annot = True,
            annot_kws = {"size": 8},
            ax = ax)

print("Положительная корреляция с признаком 'Class': V2, V4, V11 ")
print("Негативная корреляция с признаком 'Class': V3, V7, V9, V10, V12, V14, V16")

df.plot.scatter(x="Amount", y='Class')

plt.minorticks_on()
plt.grid(which='major')
plt.grid(which='minor', linestyle=':')
df['Amount'].plot(figsize=(12,6))

# график количества транзакций в зависимости от суммы ("Amount")
fig, (ax3,ax4) = plt.subplots(2,1, figsize = (6,3), sharex = True)
ax3.hist(df.Amount[df.Class==0],bins=50,color='b',alpha=0.5)
ax3.set_yscale('log')
ax3.set_title('Correct')
ax3.set_ylabel('transactions')
ax4.hist(df.Amount[df.Class==1],bins=50,color='r',alpha=0.5)
ax4.set_yscale('log')
ax4.set_title('Fraud')
ax4.set_xlabel('Amount')
ax4.set_ylabel('transactions')

# строим графики распределения плотности для каждого признака (так как некоторые распределния очень схожи (т.е. ответ 0 зависит от признака также как и ответ 1),
# есть предположение, что их можно удлать без потери качества)
import seaborn as sns
import matplotlib.gridspec as gridspec
gs = gridspec.GridSpec(28, 1)
plt.figure(figsize=(6,28*4))
for i, col in enumerate(df[df.iloc[:,0:28].columns]):
    ax5 = plt.subplot(gs[i])
    sns.distplot(df[col][df.Class == 1], bins=50, color='r')
    sns.distplot(df[col][df.Class == 0], bins=50, color='b')
    ax5.set_xlabel('')
    ax5.set_title('feature: ' + str(col))
plt.show()

"""#Перекодировка  признаков"""

df.head()

from sklearn import preprocessing
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
scalers={}
for _ in df.columns:
  if _ in ['Amount','Time','Class']:
    if _ == 'Class':
      scalers[_] = LabelEncoder()
      scalers[_].fit( df[_].values )
    else:
      scalers[_] = MinMaxScaler()
      scalers[_].fit( df[_].values.reshape(-1,1) )
  else:
    # scalers[_] = StandardScaler()
    scalers[_] = MinMaxScaler()
    scalers[_].fit( df[_].values.reshape(-1, 1) )

scalers



"""## Нормализация датасета"""

y = df['Class']
y_ = df['Class']
X = df.drop(["Class"],axis=1)

# 
# Проводим нормализацию датасета, в зависмости от типа данных
# 
# Предикторы
for _ in X.columns:
  if type(scalers[_])==LabelEncoder:
    X[_] = scalers[_].transform( df[_].values )
  else:
    X[_] = scalers[_].transform( df[_].values.reshape(-1,1) )

# Предикаты
_ = 'Class'
if type(scalers[_])==LabelEncoder:
  y_ = scalers[_].transform( df[_].values )
  y = scalers[_].transform( df[_].values )
else:
  y_ = scalers[_].transform( df[_].values.reshape(-1,1) )
  y = scalers[_].transform( df[_].values.reshape(-1,1) )

"""# Разбиение на train, test"""

from imblearn.over_sampling import SMOTE as Smote
from sklearn.model_selection import train_test_split


def imbalanced_smote(X_train, y_train):#семплирование
    return Smote().fit_resample(X_train, y_train)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)
X_train, y_train = imbalanced_smote(X_train, y_train)
print(X_train.shape, y_train.shape)

"""# Обучение модели"""

#Метрики
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, recall_score, confusion_matrix

"""###DummyClassifier"""

from sklearn import dummy
model=dummy.DummyClassifier()
model.fit(X_train, y_train)
predictions=model.predict(X_test)
print('*'*45)
print ('Model:', str(model))
print ('Accuracy:',accuracy_score(y_test, predictions))
print ('F1:', f1_score(y_test, predictions))
print ('Roc-auc:',roc_auc_score (y_test, predictions))

"""###LogisticRegression"""

from sklearn.linear_model import LogisticRegression
model=LogisticRegression(random_state=0)
model.fit(X_train, y_train)
pred_Y=model.predict(X_test)
print('*'*45)

# pred_values = []
# y_values = []
# for _ in pred_Y:
#   pred_values.append( np.argmax(_) )
# for _ in y_test:
#   y_values.append( np.argmax(_) )

print ('Model:', str(model))
print ('Accuracy:',accuracy_score(y_test, pred_Y))
print ('F1:', f1_score(y_test, pred_Y))
# print ('Roc-auc:',roc_auc_score (y_test, pred_Y))
print ('Recall score:',recall_score (y_test, pred_Y))

import matplotlib
from sklearn import metrics
fig = plt.figure(figsize=(10,8))
mtx=metrics.confusion_matrix(y_test, pred_Y)

font = {'weight' : 'bold', 'size'   :22}
matplotlib.rc('font', **font)
matplotlib.rc('xtick', labelsize=20) 
matplotlib.rc('ytick', labelsize=20) 
sns.heatmap(mtx, annot=True, fmt="d")
plt.ylabel("Real value")
plt.xlabel("Predicted value")

def plot_roc_curve(fper, tper):
    plt.plot(fper, tper, color='red', label='ROC')
    plt.plot([0, 1], [0, 1], color='green', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC-кривая')
    plt.legend()
    plt.show()

from sklearn.metrics import roc_curve
fper, tper, thresholds = roc_curve(y_test, pred_Y)
plot_roc_curve(fper, tper)

"""###RandomForestClassifier"""

print(X_train[:10])
print(y_train[:10])

from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier(max_depth=12, random_state=0, n_estimators=200)
model.fit(X_train, y_train)
pred_Y=model.predict(X_test)
print('*'*45)
print ('Model:', str(model))
print(pred_Y)
# pred_values = []
# y_values = []
# for _ in pred_Y:
#   pred_values.append( np.argmax(_) )
# for _ in y_test:
#   y_values.append( np.argmax(_) )

print ('Model:', str(model))
print ('Accuracy:',accuracy_score(y_test, pred_Y))
print ('F1:', f1_score(y_test, pred_Y))
# print ('Roc-auc:',roc_auc_score (y_test, pred_Y))
print ('Recall score:',recall_score (y_test, pred_Y))

fig = plt.figure(figsize=(10,8))
mtx_RFC=metrics.confusion_matrix(y_test, pred_Y)

font = {'weight' : 'bold', 'size'   :22}
matplotlib.rc('font', **font)
matplotlib.rc('xtick', labelsize=20) 
matplotlib.rc('ytick', labelsize=20) 
sns.heatmap(mtx_RFC, annot=True, fmt="d")
plt.ylabel("Real value")
plt.xlabel("Predicted value")

fper, tper, thresholds = roc_curve(y_test, pred_Y)
plot_roc_curve(fper, tper)

"""### Keras **CONV**"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Dropout
from keras.layers import LSTM, Embedding, Conv1D, MaxPooling1D, Flatten
from keras.layers import BatchNormalization
from tensorflow.keras.optimizers import SGD
from sklearn.metrics import mean_absolute_error, explained_variance_score
print("Num GPUs Available: ", len(tf.config.list_physical_devices('GPU')))

# scalers
_ = 'Class'
arr_len = len(scalers[_].classes_)
y=[]
for _ in y_:
  item = [0]*arr_len

  item[_] = 1
  y.append(item)

print(X[:10])
print(y[:10])

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, shuffle=True)
X_train = np.array(X_train)
X_test = np.array(X_test)
y_train = np.array(y_train)
y_test = np.array(y_test)
print(y_train[:10])

columns_count = X_train.shape[1]
# меньше батчи - лучше обучается
batch_size = 200
# обрезаем массивы по батчу
array_w_batch_size = X_train.shape[0]//batch_size*batch_size
X_train = X_train[:array_w_batch_size]
y_train = y_train[:array_w_batch_size]
array_w_batch_size = X_test.shape[0]//batch_size*batch_size
X_test = X_test[:array_w_batch_size]
y_test = y_test[:array_w_batch_size]
print('X_train',X_train.shape)
print('y_train',y_train.shape)
print('X_test',X_test.shape)
print('y_test',y_test.shape)
print(y_train[:10])
def get_model():
  model = Sequential()
  model.add(Conv1D(128, 3, batch_input_shape=(batch_size, columns_count, 1), activation="relu"))
  model.add(MaxPooling1D(pool_size=3, strides=3))
  model.add(Conv1D(128, 3, batch_input_shape=(batch_size, columns_count, 1), activation="selu"))
  model.add(MaxPooling1D(pool_size=2, strides=2))
  model.add(Flatten())
  model.add(BatchNormalization())
  model.add(Dropout(0.1))
  model.add(Dense(columns_count*10, activation='selu'))
  model.add(BatchNormalization())
  model.add(Dropout(0.1))
  model.add(Dense(columns_count*8, activation='selu'))
  model.add(BatchNormalization())
  model.add(Dropout(0.1))
  model.add(Dense(columns_count*2, activation='sigmoid'))
  model.add(BatchNormalization())
  model.add(Dropout(0.2))
  model.add(Dense(arr_len, activation='softmax'))
  opt = SGD(learning_rate=0.01, momentum=0.9)
  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
  return model

model = get_model()
model.summary()
hist = model.fit(X_train, y_train, epochs=20, batch_size=batch_size, verbose=1, validation_data=(X_test, y_test))

def plot_loss(history):
  plt.plot(history.history['loss'], label='loss')
  plt.plot(history.history['val_loss'], label='val_loss')
  # plt.ylim([0, 10])
  plt.xlabel('Epoch')
  plt.ylabel('Error [MPG]')
  plt.legend()
  plt.grid(True)
  
print(y_test[:10])
print(model.predict(X_test[:10]))
plot_loss(hist)

tf.keras.utils.plot_model(model,  show_shapes=True)

from sklearn.metrics import mean_squared_error
from sklearn.metrics import roc_curve, auc, recall_score

array_w_batch_size = X_test.shape[0]//batch_size*batch_size
X_test = X_test[:array_w_batch_size]
y_test = y_test[:array_w_batch_size]
print(X_test.shape)
print(y_test.shape)
pred_Y = model.predict(X_test)

# print(pred_Y[:10])

# надо найти категорию, значение в которой максимально. Позиция этой категории и будет ответом
pred_values = []
y_values = []
for _ in pred_Y:
  pred_values.append( np.argmax(_) )
for _ in y_test:
  y_values.append( np.argmax(_) )

print ('Model:', str(model))
print ('Accuracy:',accuracy_score(y_values, pred_values))
print ('F1:', f1_score(y_values, pred_values))
print ('Roc-auc:',roc_auc_score (y_values, pred_values))
print ('Recall score:',recall_score (y_values, pred_values))

# Вычислить кривую ROC и область ROC для каждого класса
# сохраняем вероятности только для положительного исхода
# lr_probs = lr_probs[:, 1]
# рассчитываем ROC AUC
# рассчитываем roc-кривую
fpr, tpr, treshold = roc_curve(y_values, pred_values)
roc_auc = auc(fpr, tpr)
# строим график
plt.plot(fpr, tpr, color='darkorange',
         label='ROC кривая (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC-прямая')
plt.legend(loc="lower right")
plt.show()

mtx_RFC=metrics.confusion_matrix(y_values, pred_values)

font = {'weight' : 'bold', 'size'   :22}
matplotlib.rc('font', **font)
matplotlib.rc('xtick', labelsize=20) 
matplotlib.rc('ytick', labelsize=20) 
sns.heatmap(mtx_RFC, annot=True, fmt="d")
plt.ylabel("Real value")
plt.xlabel("Predicted value")

"""# NaiveBayes"""

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, shuffle=True)
X_train = np.array(X_train)
X_test = np.array(X_test)
y_train = np.array(y_train)
y_test = np.array(y_test)
# print(X_train[:5])
# print(y_train[:5])


from sklearn.naive_bayes import GaussianNB,CategoricalNB,ComplementNB,BernoulliNB,MultinomialNB
for mdl_ in [ GaussianNB(), ComplementNB() ]:
  model = mdl_.fit(X_train, y_train)
  pred_Y = model.predict(X_test)
  print ('Model:', str(model))
  print ('Accuracy:',accuracy_score(y_test, pred_Y))
  print ('F1:', f1_score(y_test, pred_Y))
  print ('Roc-auc:',roc_auc_score (y_test, pred_Y))
  print ('Recall score:',recall_score (y_test, pred_Y))

  fig = plt.figure(figsize=(10,8))
  mtx_RFC=confusion_matrix(y_test, pred_Y)
  font = {'weight' : 'bold', 'size'   :22}
  matplotlib.rc('font', **font)
  matplotlib.rc('xtick', labelsize=20) 
  matplotlib.rc('ytick', labelsize=20) 
  sns.heatmap(mtx_RFC, annot=True, fmt="d")
  plt.title(str(model))
  plt.ylabel("Real value")
  plt.xlabel("Predicted value")
  
  print("")

gnb = GaussianNB()
model = gnb.fit(X_train, y_train)

pred_Y = model.predict(X_test)

# print(pred_Y[:10])

# надо найти категорию, значение в которой максимально. Позиция этой категории и будет ответом
# pred_values = []
# y_values = []
# for _ in pred_Y:
#   pred_values.append( np.argmax(_) )
# for _ in y_test:
#   y_values.append( np.argmax(_) )

print ('Model:', str(model))
print ('Accuracy:',accuracy_score(y_test, pred_Y))
print ('F1:', f1_score(y_test, pred_Y))
print ('Roc-auc:',roc_auc_score (y_test, pred_Y))
print ('Recall score:',recall_score (y_test, pred_Y))

fig = plt.figure(figsize=(10,8))
mtx_RFC=confusion_matrix(y_test, pred_Y)

font = {'weight' : 'bold', 'size'   :22}
matplotlib.rc('font', **font)
matplotlib.rc('xtick', labelsize=20) 
matplotlib.rc('ytick', labelsize=20) 
sns.heatmap(mtx_RFC, annot=True, fmt="d")
plt.ylabel("Real value")
plt.xlabel("Predicted value")